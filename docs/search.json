[
  {
    "objectID": "content/PamguardProcessing.html",
    "href": "content/PamguardProcessing.html",
    "title": "Pamguard Processing",
    "section": "",
    "text": "Summary\nPamgaurd version 2.02.14 was used to process all drifting acoustic buoy recordings in order to collect click data for both sperm whales and beaked whales.\n\n\nBeaked Whales",
    "crumbs": [
      "Analysis",
      "Pamguard Processing"
    ]
  },
  {
    "objectID": "content/folderStructure.html",
    "href": "content/folderStructure.html",
    "title": "Folder Structure & Content",
    "section": "",
    "text": "This template provides a set of standard folders for specific types of files. We recommend following these standard approaches as consistency allows us to follow each other‚Äôs research workflow.\nHere we further explain how to work with this folder structure, with tips and tricks to make your work more accessible, reproducible, and to help Future You!",
    "crumbs": [
      "Folder Structure & Content"
    ]
  },
  {
    "objectID": "content/folderStructure.html#manuscript",
    "href": "content/folderStructure.html#manuscript",
    "title": "Folder Structure & Content",
    "section": "üìÅ manuscript",
    "text": "üìÅ manuscript\nManuscript for Report. This may contain one or more versions of the manuscript in one or more formats. This folder does not serve as the output location for rendered versions of the manuscript (those would be saved in the docs folder). Typically, this would be reserved for final manuscripts or manuscripts saved in an alternative format or manually modified (not direct rendered output).",
    "crumbs": [
      "Folder Structure & Content"
    ]
  },
  {
    "objectID": "content/folderStructure.html#content",
    "href": "content/folderStructure.html#content",
    "title": "Folder Structure & Content",
    "section": "üìÅ content",
    "text": "üìÅ content\nThis Research Compendium template is formatted for a HTML (website) output, and all chapters/sections for online report should reside in this content folder.",
    "crumbs": [
      "Folder Structure & Content"
    ]
  },
  {
    "objectID": "content/folderStructure.html#figs",
    "href": "content/folderStructure.html#figs",
    "title": "Folder Structure & Content",
    "section": "üìÅ figs",
    "text": "üìÅ figs\nContains all figures generated for the analysis. Your code to create figures should be saved in the code folder, and it should automatically save figure output directly to this figs folder. All figure names should be descriptive not based on the # of the figure (as this may change).",
    "crumbs": [
      "Folder Structure & Content"
    ]
  },
  {
    "objectID": "content/folderStructure.html#docs",
    "href": "content/folderStructure.html#docs",
    "title": "Folder Structure & Content",
    "section": "üìÅ docs",
    "text": "üìÅ docs\nContains rendered versions of the reports (if applicable). Note that this is different from the manuscript folder, which would have version(s) of the manuscript not rendered directly from the repository.\n\n\n\n\n\n\nNote: Need to check if this is relevant for this particular HTML output format",
    "crumbs": [
      "Folder Structure & Content"
    ]
  },
  {
    "objectID": "content/folderStructure.html#data",
    "href": "content/folderStructure.html#data",
    "title": "Folder Structure & Content",
    "section": "üìÅ data",
    "text": "üìÅ data\nContains ORIGINAL raw or raw-derived data. Github is NOT an appropriate platform for saving large files or large numbers of files. You will need to save your raw data (and possible other large data products) in an alternative location, such as NCEI, Figshare, or Zenodo. We recommend that you identify the location of all raw data (WHERE?). As this data is intended to be ORIGINAL data, we recommend that modified or intermediate data or data products (that are modified by code stored in the code folder) be stored in the output folder.\n\n\n\n\n\n\nNote: Where do we recommend that they identify the location of any data or data products not directly saved to this repository? In the readme? or the index file?",
    "crumbs": [
      "Folder Structure & Content"
    ]
  },
  {
    "objectID": "content/folderStructure.html#output",
    "href": "content/folderStructure.html#output",
    "title": "Folder Structure & Content",
    "section": "üìÅ output",
    "text": "üìÅ output\nThis can include any modified or intermediate data or data products (data in data folder is ORIGINAL), and data in output may be modified using code stored in code folder.",
    "crumbs": [
      "Folder Structure & Content"
    ]
  },
  {
    "objectID": "content/folderStructure.html#code",
    "href": "content/folderStructure.html#code",
    "title": "Folder Structure & Content",
    "section": "üìÅ code",
    "text": "üìÅ code\nScripts that actually do things. If using R, your script should use the here package rather than setwd() to build paths to files and allow for more efficient reproduction of workflow. Script should automatically access data in the data folder and save output to relevant folders (output, figs).\n\n_commonR.R\nWe recommend saving commonly used functions in the _commonR.R file (assuming you are using R for your analysis‚Äì if not, you can delete this file). This is a good place to identify the libraries to load, any themes or common formatting requirements, or other common functions. Ideally these types of functions are only located in one place, so that they only need to be changed in one place. You can then source this file in other code (reduces redundancy and allows you to modify these basic functions in one place instead of throughout your various scripts).",
    "crumbs": [
      "Folder Structure & Content"
    ]
  },
  {
    "objectID": "content/folderStructure.html#supplement",
    "href": "content/folderStructure.html#supplement",
    "title": "Folder Structure & Content",
    "section": "üìÅ supplement",
    "text": "üìÅ supplement\nSupplementary files that are not data, script, or components of the manuscript.",
    "crumbs": [
      "Folder Structure & Content"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "California Current Cetacean and Ecosystem Assessment Survey Passive Acoustic Analysis",
    "section": "",
    "text": "subtitle: ‚ÄúA research compendium for the passive acoustics component of CalCurCEAS‚Äù page-layout: full",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "The Passive Acoustic Analysis for the California Current Cetacean and Ecosystem Assessment Survey (CalCurCEAS)",
    "section": "Overview",
    "text": "Overview\nThe 2024 California Current Cetacean and Ecosystem Assessment Survey (CalCurCEAS) was conducted by the Marine Mammal and Turtle Division (MMTD) of Southwest Fisheries Science Center (SWFSC). The survey was conducted over the course of 6 legs aboard the M/V Bold Horizon between July 24th and December 5th 2024. The primary objectives of CalCurCEAS 2024 was to collect visual sightings data for marine mammals and seabirds, passive acoustic data for cetaceans, biopsy tissue samples for cetaceans and environmental DNA samples. These datasets will be used for a suite of analyses that support MMTD‚Äôs fulfillment of regulatory requirements and scientific initiatives, such as marine mammal stock assessments for stakeholders such as the US Navy and BOEM.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#drifting-acoustic-recorders-in-the-california-current",
    "href": "index.html#drifting-acoustic-recorders-in-the-california-current",
    "title": "The Passive Acoustic Analysis for the California Current Cetacean and Ecosystem Assessment Survey (CalCurCEAS)",
    "section": "Drifting Acoustic Recorders in the California Current",
    "text": "Drifting Acoustic Recorders in the California Current\nThe passive acoustics component of CalCurCEAS 2024 was comprised of deploying drifting acoustic recording buoys at predetermined locations in the survey area. Buoys were deployed on all legs except for leg 1 due to it‚Äôs transitory nature (re-positioning the vessel from San Diego to the north end of the study area).",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "content/DataQualityCheck.html",
    "href": "content/DataQualityCheck.html",
    "title": "Data Prep and Quality Check",
    "section": "",
    "text": "After each drifting buoy deployment, SUD files (compressed audio file with recording metadata) were offloaded from each recording device. The SUD files were extracted using Soundtrap Host software file extraction tool (version ___). The exported files include raw audio files (.wav), recording logs, and accelerometer data.\n\n\n\nTo prep for analysis, the data were decimated and Long Term Spectral Averages (LTSA) were created. Data were decimated to 48 kHz, 12 kHz, and 500 Hz using the Matlab based Triton Software Package. LTSAs were also made for each dataset with the following parameters;\n\n384 kHz (raw data): 5 seconds, 200 Hz\n48 kHz: 5 seconds, 1 Hz\n12 kHz: 5 seconds, 1 Hz\n500 Hz: 1 seconds, 1 Hz\n\nThe data start and end times were also determined from the full bandwidth LTSAs and the data was truncated before anaylsis.",
    "crumbs": [
      "Data Managment and Archive",
      "Data Prep and Quality Check"
    ]
  },
  {
    "objectID": "content/DataQualityCheck.html#data-prep",
    "href": "content/DataQualityCheck.html#data-prep",
    "title": "Data Prep and Quality Check",
    "section": "",
    "text": "After each drifting buoy deployment, SUD files (compressed audio file with recording metadata) were offloaded from each recording device. The SUD files were extracted using Soundtrap Host software file extraction tool (version ___). The exported files include raw audio files (.wav), recording logs, and accelerometer data.\n\n\n\nTo prep for analysis, the data were decimated and Long Term Spectral Averages (LTSA) were created. Data were decimated to 48 kHz, 12 kHz, and 500 Hz using the Matlab based Triton Software Package. LTSAs were also made for each dataset with the following parameters;\n\n384 kHz (raw data): 5 seconds, 200 Hz\n48 kHz: 5 seconds, 1 Hz\n12 kHz: 5 seconds, 1 Hz\n500 Hz: 1 seconds, 1 Hz\n\nThe data start and end times were also determined from the full bandwidth LTSAs and the data was truncated before anaylsis.",
    "crumbs": [
      "Data Managment and Archive",
      "Data Prep and Quality Check"
    ]
  },
  {
    "objectID": "content/DataQualityCheck.html#qaqc",
    "href": "content/DataQualityCheck.html#qaqc",
    "title": "Data Prep and Quality Check",
    "section": "QAQC",
    "text": "QAQC\nThe full bandwidth LTSAs were used to assess the overall data quality as good, compromised, or unusable.\nA recording QAQC was also run to identify abnormal file sizes, gaps in the recordings, or other recording abnormalities. This QAQC was ran using a custom Matlab script (PAMmisc QAQC R version).",
    "crumbs": [
      "Data Managment and Archive",
      "Data Prep and Quality Check"
    ]
  },
  {
    "objectID": "content/DataQualityCheck.html#noise-assessment",
    "href": "content/DataQualityCheck.html#noise-assessment",
    "title": "Data Prep and Quality Check",
    "section": "Noise Assessment",
    "text": "Noise Assessment\nUsing the Triton Logger remora, the 384 kHz LTSAs were manually scanned to log time periods with noisy or compromised data, which would be excluded from analysis.",
    "crumbs": [
      "Data Managment and Archive",
      "Data Prep and Quality Check"
    ]
  },
  {
    "objectID": "content/DataUpload.html",
    "href": "content/DataUpload.html",
    "title": "Data Upload & Archive",
    "section": "",
    "text": "All metadata, raw audio data, and data products are stored locally on the DON shared network drive (\\\\swc-storage4-s, MMTD-ACOUSTICS). This includes the following;\n\nextracted SUD files (log, wav, accelerometer)\ndepth data\nGPS data\nQAQC results\ndecimated data\nLTSAs\nanalysis data products\n\nCompressed SUD files are stored locally to the PAM Synology drive.\nDeployment metadata is also archived to a local Tethys database. Detailed directions to access this database here.",
    "crumbs": [
      "Data Managment and Archive",
      "Data Upload & Archive"
    ]
  },
  {
    "objectID": "content/DataUpload.html#local-archive",
    "href": "content/DataUpload.html#local-archive",
    "title": "Data Upload & Archive",
    "section": "",
    "text": "All metadata, raw audio data, and data products are stored locally on the DON shared network drive (\\\\swc-storage4-s, MMTD-ACOUSTICS). This includes the following;\n\nextracted SUD files (log, wav, accelerometer)\ndepth data\nGPS data\nQAQC results\ndecimated data\nLTSAs\nanalysis data products\n\nCompressed SUD files are stored locally to the PAM Synology drive.\nDeployment metadata is also archived to a local Tethys database. Detailed directions to access this database here.",
    "crumbs": [
      "Data Managment and Archive",
      "Data Upload & Archive"
    ]
  },
  {
    "objectID": "content/DataUpload.html#ncei",
    "href": "content/DataUpload.html#ncei",
    "title": "Data Upload & Archive",
    "section": "NCEI",
    "text": "NCEI\nRaw audio data and deployment metadata are archived to NCEI Passive Acoustic Data Archive.\nLink to archived data once uploaded.",
    "crumbs": [
      "Data Managment and Archive",
      "Data Upload & Archive"
    ]
  },
  {
    "objectID": "content/DataUpload.html#pacm",
    "href": "content/DataUpload.html#pacm",
    "title": "Data Upload & Archive",
    "section": "PACM",
    "text": "PACM\nOnce finalized, beaked whale and sperm whale detections will be archived to NEFSC Passive Acoustic Cetacean Map",
    "crumbs": [
      "Data Managment and Archive",
      "Data Upload & Archive"
    ]
  }
]